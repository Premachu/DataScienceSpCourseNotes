{
    "contents" : "---\ntitle: \"Socio-economic impacts of severe storms and weather\"\nauthor: \"Prem\"\ndate: \"Saturday, January 09, 2016\"\noutput:\n  html_document:\n    highlight: pygments\n    toc: yes\n---\n\n## Uselful links\n\n* Layout (variable names) [link](https://github.com/mat4med/RepData_PeerAssessment2)  \n* Date range [link] (https://www.ncdc.noaa.gov/stormevents/details.jsp?type=eventtype): all events are only recorded from 1996 onwards \n* \n\n## Read in Data\n\n```\nif(!file.exists(\"data\"){dir.create(\"data\")}\n   url <- \"https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2\"\n   download.file(url, destfile= \"data/storm.csv.bz2\")\n```\n\n## Get idea of data\n\n```{r, cache=TRUE}\ndf <- read.csv(\"data/storm.csv.bz2\")\ndfMaster <- df # Mastercopy\n\n## see structure of data\n\nstr(df)\ntable(df$EVTYPE) # Order events by most occuring\n```\n\n## Clean up data. \n\n### Remove early records (retain 1996 onwards)\nFirst convert the date column from chr into a date format. Note that forward slash seperators are needed or else the date will not formart correctly.\n* `...\"%m/%d/%Y\"` = correct formatting\n* `...\"%m %d %Y\"` = wrong formatting\n\n```{r}\n# Convert date column from character class to date\ndf$BGN_DATE2 <- as.Date(df$BGN_DATE, \"%m/%d/%Y\")\n# Subset dates after 1996\ndf96 <- subset(df, BGN_DATE2 > as.Date(\"1996-01-01\")) \n```\n\n### create subset of random sample for exploratory analysis / test code\n\n```{r}\nrow.sample <- function(dta, rep = 20) {\n  dta <- as.data.frame(dta) # for single variables\n  dta[sample(1:nrow(dta), rep, replace=FALSE), ] \n} \ndfsample <- row.sample(df96, 1000)\n```\n\n### clean EV variable type\n\n```{r}\n\nlength(unique(df96$EVTYPE))# there is round 800 (400 is subsetted by date) event type names\nunique(df96$EVTYPE)\n\n## Official 48 event types\nevents <- readLines(\"data/event.txt\")\nevents <- gsub(\"[C|Z|M|]$\", \"\", events) # remove designator (Country, Zone, Marine)\nevents <- gsub(\" $\", \"\", events) # Remove space from end\n\n## Table of recorded events using plyr rather than `table()`\nlibrary(plyr)\nevents_recorded <- count(df96, \"EVTYPE\")\n\n## Match recorded events to official 48 events\nlibrary(stringdist)\n\n# make official event names and original names uppercase\nevents_recorded$EVTYPE <- toupper(events_recorded$EVTYPE)\nevents <- toupper(events)\n\n# match data\nmatch2 <- amatch(events_recorded$EVTYPE, events, maxDist=2)\n\n# append to recorded_events table\nevents_recorded[,\"match2\"] <- match2\nevents_recorded[,\"evmatch\"] <- events[events_recorded$match2]\n```\n\nCheck % of matched data. I.e. number of matched values / total number of values. This gives a 72% match (with original, non-96 data. It is 77% with post 96 data)\n\n```{r}\nmatched <- which(!is.na(events_recorded$evmatch))\nsum(events_recorded$freq[matched])/sum(events_recorded$freq) \n```\n\nNow, let's clean up the top 150 vars that account for 99% of data, which `amatch` missed.  \n\n```{r}\nhead(events_recorded[order(-events_recorded$freq),],50)\n```\n\n```{r}\nevents_recorded[grep(\".*^TSTM.*\", events_recorded$EVTYPE, ignore.case = TRUE),]$evmatch <- \"THUNDERSTORM WIND\"\n\nevents_recorded[grep(\".*^MARINE TSTM.*\", events_recorded$EVTYPE, ignore.case = TRUE),]$evmatch <- \"MARINE THUNDERSTORM WIND\"\n\nevents_recorded[grep(\".*^URBAN/SML STREAM FLD.*\", events_recorded$EVTYPE, ignore.case = TRUE),]$evmatch <- \"FLOOD\"\n\nevents_recorded[grep(\".*flash flood.*\", events_recorded$EVTYPE, ignore.case = TRUE,),]$evmatch <- \"FLASH FLOOD\"\n\nevents_recorded[grep(\"winter weather|.*wintr.*\", events_recorded$EVTYPE, ignore.case = TRUE),]$evmatch <- \"WINTER WEATHER\"\n\nevents_recorded[grep(\".*FIRE.*\", events_recorded$EVTYPE, ignore.case = TRUE),]$evmatch <- \"WILDFIRE\"\n```\n\nMaking the above changes makes data 98% full. \n\n# join \n\n```{r}\nlibrary(dplyr)\n\n# Change EVTYPE from factor to character for join\ndf96$EVTYPE <-as.character(df96$EVTYPE)\n\n# `unique` is needed because of duplicates from making `EVTYPE` uppercase\ndf_new <- left_join(df96, unique(events_recorded[,c(1,3,4)]), by = c(\"EVTYPE\"))\n\n## Fill in NA's of evmatch with value from EVTYPE\ndf_new$evmatch <- with(df_new, ifelse(is.na(evmatch), EVTYPE, evmatch))\n\n# Change EVTYPE back to factor\ndf_new$evmatch <- as.factor(df_new$evmatch)\n```\n\n\n## Make two new datasubsets for economic and health impacts\n\n# Edit exponents\n\n```{r}\nunique(df_new$PROPDMGEXP)\nunique(df_new$CROPDMGEXP)\n# Change exponents from factor to chr\ndf_new[,26] <- as.character(df_new[,26])\ndf_new[,28] <- as.character(df_new[,28])\n\ndf_new[,26] <- toupper(df_new[,26])\ndf_new[,28] <- toupper(df_new[,28])\n\n## There is a typo for nappa flood, where the exp was written as \"B\" not \"M\"\ndf_new$PROPDMGEXP[357163] <- \"M\"\n\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"-\"] <- 0\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"?\"] <- 0\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"+\"] <- 0\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"\"]  <- 0\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"h\"] <- 2\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"H\"] <- 2\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"K\"] <- 3\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"m\"] <- 6\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"M\"] <- 6\n  df_new$PROPDMGEXP[df_new$PROPDMGEXP==\"B\"] <- 9\n\n  \n\n  df_new$CROPDMGEXP[df_new$CROPDMGEXP == \"K\"] <- 3\n  df_new$CROPDMGEXP[df_new$CROPDMGEXP == \"M\"] <- 6\n  df_new$CROPDMGEXP[df_new$CROPDMGEXP == \"B\"] <- 9\n  df_new$CROPDMGEXP[df_new$CROPDMGEXP == \"\"]  <- 0\n  \ndf_new[,26] <- as.integer(df_new[,26])\ndf_new[,28] <- as.integer(df_new[,28])\n  \n  df_new$CROPDMG <- df_new$CROPDMG*10^df_new$CROPDMGEXP\n  df_new$PROPDMG <- df_new$PROPDMG*10^df_new$PROPDMGEXP\n\n# Create damage dataset\n\ndamage<- df_new[c(38,40, 25:28,36)]\n\nmax(damage$PROPDMG)\nmax(damage$CROPDMG)\ndamage[which.max(damage$PROPDMG),] # hurricane katrina. 31300000000  \ndamage[which.max(damage$CROPDMG),] # hurricane katrina. 1510000000 \n\n```\n\nmake health dataset\n\n```{r}\n\nhealth <- df_new[c(38,40, 23:24,36)]\n\nmax(health$FATALITIES)\nmax(health$INJURIES)\nhealth[which.max(health$FATALITIES),] # hurricane katrina. 31300000000  \nhealth[which.max(health$INJURIES),] # hurricane katrina. 1510000000\n\n```\n\n## Another method: Make dataset for each variable, using the extreme events\n\n```{r}\n### EXTREME FATALITIES\n# we could use extreme value theorem to model the tails of the distribution I think...\n# first we select the very extreme values (as represented by the 0.999 quantile)\nhigh.fatality.events <-df_new[df_new$FATALITIES > quantile(df_new$FATALITIES, 0.999), c('BGN_DATE2', 'STATE', 'evmatch', 'FATALITIES', 'REMARKS')] \n\nhigh.fatality.events <- high.fatality.events[ order(high.fatality.events$FATALITIES, decreasing=TRUE), ]\n\n# Turn evmatch to from chr to factor, in order to return useful summary analysis data for `evmatch` (already converted before in df_new, but i'm leaving this note in so we know why)\n\n# high.fatality.events$evmatch<-as.factor(high.fatality.events$evmatch)\n\nsummary(high.fatality.events)\n\n### EXTREME INJURIES\nhigh.injury.events <- df_new[df_new$INJURIES > quantile(df_new$INJURIES, 0.999), c('BGN_DATE2', 'STATE', 'evmatch', 'INJURIES', 'REMARKS')]\n\nhigh.injury.events <- high.injury.events[ order(high.injury.events$INJURIES, decreasing = TRUE), ]\nsummary(high.injury.events)\n\n### EXTREME PROPERTY DAMAGE\n# we could use extreme value theorem to model the tails of the distribution I think...\n# first we select the very extreme values (as represented by the 0.999 quantile)\nhigh.property.damage.events <- df_new[df_new$PROPDMG > quantile(df_new$PROPDMG, 0.999), c('BGN_DATE2', 'STATE', 'evmatch', 'PROPDMG', 'REMARKS')]\n\nhigh.property.damage.events <- high.property.damage.events[ order(high.property.damage.events$PROPDMG, decreasing = TRUE), ]\nsummary(high.property.damage.events[,-5])\n\n# Crop\nhigh.crop.damage.events <- df_new[df_new$CROPDMG > quantile(df_new$CROPDMG, 0.999), c('BGN_DATE2', 'STATE', 'evmatch', 'CROPDMG', 'REMARKS')]\n\nhigh.crop.damage.events <- high.crop.damage.events[ order(high.crop.damage.events$CROPDMG, decreasing = TRUE), ]\nsummary(high.crop.damage.events[,-5])\nhead(high.crop.damage.events[,-5], 10)\n```\n\nStates most affected by floods are low-lying coastal areas, whereas areas affected by tornatoes and extreme heat are on the western states.\n\nMake graph showing this\n\n```{r}\n\n# What are the top-5 most frequent causes of events resulting in very high fatalities\nbarplot(head(sort(table(high.fatality.events$evmatch), decreasing=TRUE), 5), \n        las=2, main='Causes of high-fatality\\n(p < 0.001) events')\n\n# What are the top-5 most frequent locations of events resulting in very high fatalities\nbarplot(sort(table(high.fatality.events$STATE), decreasing=TRUE)[1:5],\n        main='Occurence of high-fatality events\\n(p < 0.001) events by state', las=2)\n\n# What are the top-5 most frequent causes of events resulting in very high injuries\nbarplot(head(sort(table(high.injury.events$evmatch), decreasing=TRUE), 5), \n        las=2, main='Causes of high-injury\\n(p < 0.001) events')\n\n# What are the top-5 most frequent locations of events resulting in very high injuries\nbarplot(sort(table(high.injury.events$STATE), decreasing=TRUE)[1:5],\n        main='Occurence of high-injury events\\n(p < 0.001) events by state', las=2)\n\n# What are the top-5 most frequent causes of events resulting in very high property damage\nbarplot(head(sort(table(high.property.damage.events$evmatch), decreasing=TRUE), 5), \n        las=2, main='Causes of high-property damage\\n(p < 0.001) events')\n\n# What are the top-5 most frequent locations of events resulting in very high property damage\nbarplot(sort(table(high.property.damage.events$STATE), decreasing=TRUE)[1:5],\n        main='Occurence of high-property damage events\\n(p < 0.001) events by state', las=2)\n\n# What are the top-5 most frequent causes of events resulting in very high crop damage\nbarplot(head(sort(table(high.crop.damage.events$evmatch), decreasing=TRUE), 5), \n        las=2, main='Causes of high-crop damage\\n(p < 0.001) events')\n\n# What are the top-5 most frequent locations of events resulting in very high crop damage\nbarplot(sort(table(high.crop.damage.events$STATE), decreasing=TRUE)[1:5],\n        main='Occurence of high-crop damage events\\n(p < 0.001) events by state', las=2)\n        \n```\n\n# let's examine how the impact of our top causes of fatalities have evolved with time\nfatalities.by.evtype <- aggregate(FATALITIES ~ evmatch + format(BGN_DATE2, '%Y'), df_new, sum)\nfatalities.by.evtype <- setNames(fatalities.by.evtype, c('evtype', 'year', 'total.fatalities'))\nfatalities.by.evtype <- fatalities.by.evtype[ fatalities.by.evtype$evtype %in% c('TORNADO', 'HEAT', 'FLOOD', 'COLD', 'HURRICANE'), ]\nl <- split(fatalities.by.evtype, f = factor(fatalities.by.evtype$evtype))\nplot(x=0, y=0, type='n', \n     xlim = c(min(as.numeric(fatalities.by.evtype$year)), max(as.numeric(fatalities.by.evtype$year))),\n     ylim = c(min(as.numeric(fatalities.by.evtype$total.fatalities)), max(as.numeric(fatalities.by.evtype$total.fatalities))),\n     main = 'Top 5 Causes of High-Fatality Events',\n     xlab = 'Year',\n     ylab = 'Total Fatalities')\nc <- 1\nlapply(l , function(x) { lines(x$year, x$total.fatalities, col=c, lwd=2, lty=1); c <<- c + 1 })\nlegend(x = 'topleft', legend = names(lapply(l , '$', 'evtype')), lty=1, col=1:5, lwd=2)\n\n# let's examine how the impact of our top causes of injuries have evolved with time\ninjuries.by.evtype <- aggregate(INJURIES ~ evmatch + format(BGN_DATE2, '%Y'), df_new, sum)\ninjuries.by.evtype <- setNames(injuries.by.evtype, c('evtype', 'year', 'total.fatalities'))\ninjuries.by.evtype <- injuries.by.evtype[ injuries.by.evtype$evtype %in% c('TORNADO', 'HEAT', 'FLOOD', 'THUNDERSTORM', 'STORM WINTER'), ]\nl <- split(injuries.by.evtype, f = factor(injuries.by.evtype$evtype))\nplot(x=0, y=0, type='n', \n     xlim = c(min(as.numeric(injuries.by.evtype$year)), max(as.numeric(injuries.by.evtype$year))),\n     ylim = c(min(as.numeric(injuries.by.evtype$total.fatalities)), max(as.numeric(injuries.by.evtype$total.fatalities))),\n     main = 'Top 5 Causes of High-Injury Events',\n     xlab = 'Year',\n     ylab = 'Total Injuries')\nc <- 1\nlapply(l , function(x) { lines(x$year, x$total.fatalities, col=c, lwd=2, lty=1); c <<- c + 1 })\nlegend(x = 'topleft', legend = names(lapply(l , '$', 'evtype')), lty=1, col=1:5, lwd=2)\n\nMy old original method. Not so great...\n\n```{r}\nlibrary(dplyr)\nadav <- df_new %>%\n    group_by(EVTYPE) %>%\n    summarize(mean.f =mean(FATALITIES), sum.f=sum(FATALITIES),\n    mean.i = mean(INJURIES), sum.i=sum(INJURIES),\n    sum.pdmg = sum(PROPDMG),mean.pdmg = mean(PROPDMG),\n    sum.cdmg = sum(CROPDMG), mean.pdmg = mean(CROPDMG)) %>%\n    arrange(desc(sum.pdmg))\n```\n\nHurricanes/typhoons have killed less before overall but are more deadly. Each tornado is less severe to human life, but overall more frequent and kill more people.\nHurricans cause the most property damage, but floods cause most crop damage. \n\n\n```\n\n## Create list of changed event types, non matched event types are listed as NA\ntmp <- events[(amatch(evtype, events,  maxDist= 2))]\n## How many events have failed to match? 15795 out of 653507\ncondition <- which(!is.na(events_recorded$match2)) # is not NA\nsum(events_recorded$freq[condition])/sum(events_recorded$freq)\n## Which NAs, aka event types, need to be manually changed?\nnames(table(subset(evtype, is.na(tmp))))\n```\n\n### Make all values in df$EVTYPE lower case and plural (snip off s)\n\nA lot of events are repeated due to different spelling. Change all writing to lowercase? Similar to issue with `Ged` and `ged`. This means that \"hail\" and \"hails\" are treated differently, although being the same event. There are also issues such as events beggining with a space or ending with a symbol.\n\n1. First turn all events into lowercase\n2. Remove spaces from front of events\n3. Remove plurals (words that end in s\n4. Remove symbols from the end of words \n- Unbalanced paranthesis, full stops, slashes\n\n```{r}\n# Make lower Case\ndf$EVTYPE <- tolower(df$EVTYPE)\n```\n\nEdit lines that start with spaces\n\n```{r}\n# Find lines that start with spaces, then remove space\ngrep(\"^ \",df$EVTYPE, value = T)\ndf$EVTYPE <- gsub(\" \", \"\", df$EVTYPE)\n```\n\n113 lines end in \"s\", let's snip off the s from all of them.\n\n```{r}\n# Find lines that end with `s`\ntable(grep(\"s$\",df$EVTYPE, ignore.case = TRUE, value = T))\n# Remove the `s` from words that end in s. \ndf$EVTYPE <- gsub(\"s$\",\"\", df$EVTYPE, ignore.case = T, perl=T)\n```\n\nFirst we'll find all lines that end with a symbol that isn't between a-z or 0-9. Results show lines that end in full stops, forward slashes, `-`, \n\n```{r}\n# Find lines that end with symbols (values that are not letters or nurmeric)\nnames(table(grep(\"[^A-z|0-9]$\",df$EVTYPE, value = T)))\n# Find and remove lines that end in full stop\ngrep(\"[.]$\", df$EVTYPE, value = T)\ndf$EVTYPE <- gsub(\"[.]$\",\"\", df$EVTYPE, ignore.case = T, perl=T)\n# Find and remove lines that end in forward slash\ngrep(\"[/]$\", df$EVTYPE, value = T)\ndf$EVTYPE <- gsub(\"[/]$\",\"\", df$EVTYPE, ignore.case = T, perl=T)\n# Find and remove lines that end in a dash\ngrep(\"[-]$\", df$EVTYPE, value = T)\ndf$EVTYPE <- gsub(\"[-]$\",\"\", df$EVTYPE, ignore.case = T, perl=T)\n\n================\n  Test. It should return all words except cat, because cat is not similar to anything else (i.e. cat has a distance larger than 2 to all words)\n\ntext <- c(\"ChicKen120\",\"Chicken1.20\",\"Chicken(1.20)\",\"Cow\",\"cow.\", \"cow/\", \"cat\")\ntext\nadist(text) # cat has a distance of >3\nwhich(adist(text)<=2 & upper.tri(adist(text)), arr.ind=T)     \nwords <- text[which(adist(text)<=2 & upper.tri(adist(text)), arr.ind=T)] # #do not run matrix, that way data stays as single vector/column. Now run #unique to remove repeats\nunique(words)\n\n## Find words that end in a number or paranthesis (most likely to have typo), save it to object called text and then look at similarity\n\ntext <- names(table(grep(\"[)|0-9]$\",df$EVTYPE, value = T)))\nwhich(adist(text)<=2 & upper.tri(adist(text)), arr.ind=T)\nwords <- text[which(adist(text)<=2 & upper.tri(adist(text)), arr.ind=T)]\nwords <- unique(words)\n\n===============\nchange all instances of hail(0.75) to one format\ngrep(\"hail|75\", words, value = T)\n\n```\n\n## Find the total/average impact of events for population health (fatalities/injuries) and economic impact (propdmg, cropdmg)\n\n```{r}\nlibrary(dplyr)\nadav <- df %>%\n    group_by(EVTYPE) %>%\n    summarize(mean.f =mean(FATALITIES), sum.f=sum(FATALITIES),\n    mean.i = mean(INJURIES), sum.i=sum(INJURIES),\n    sum.pdmg = sum(PROPDMG),mean.pdmg = mean(PROPDMG),\n    sum.cdmg = sum(CROPDMG), mean.pdmg = mean(CROPDMG)) %>%\n    arrange(desc(sum.pdmg))\n```\n\n\nIn total, tornadoes cause most fatalities and injuries. On average, heat waves cause most injuries per event and tornadoes/wind/hail cause most fatalities per event. \n\nThis means that while tornadoes have the largest overall impact, heat wave events are create more injuries per event.\n\n```{r}\nadav[which.max(adav$mean.f),]\nadav[which.max(adav$mean.i),]\nadav[which.max(adav$sum.f),]\nadav[which.max(adav$sum.i),]\n```\n\nOur results contain summaries for months, which are not required. Remove these. Note: the `grep` result includes `Blizzard Summary` which we want to keep, hence `)[-1],]`. \n\n```{r}\nsumlines <- which(adav$EVTYPE == \"Summary\") \nsumlines\n# `-grep...` remove all lines which have monthly summaries. \n# `...ignore.case = TRUE)[-1]` do not include \"Blizzard Summary\" in removal.\nadav <- adav[-grep(\"summary\", adav$EVTYPE, ignore.case = TRUE)[-1],]\n```\n\nThere's a few event types that begin with a space. Let's remove the space.\n\n```{r}\n# find lines that begin with a space `\"^ \"`\ngrep(\"^ \",adav$EVTYPE)\n# remove space from start of lines in EVTYPE var. \nadav$EVTYPE <- gsub(\" \", \"\", adav$EVTYPE)\n\n# Find lines that end with `s`\ngrep(\"s$\",tmp$EVTYPE, ignore.case = TRUE, value = T)\n# Remove the `s` from words that end in s. \ntmp$EVTYPE <- gsub(\"s$\",\"\", tmp$EVTYPE, ignore.case = T, perl=T)\ngrep(\"[^A-z|0-9]|\\( [0-9] \\)$\",tmp$EVTYPE, value = T)\n\n county2 <- gsub(\" $\",\"\", county, perl=T)\n\ngrep(\"\\b(\\w+)\\r\\1S\",adav$EVTYPE, ignore.case = TRUE, value = T)\n\n\\b(\\w+)\\r\\1S\n\n```\n\n## Use a plot to show which event causes most pop and eco impact\n\n## Problems\n\nA lot of events are repeated due to different spelling. Change all writing to lowercase? Similar to issue with `Ged` and `ged` \n\n- Make everything lower-case\n- Remove plurals, make it all singular\n  + `funnels` -> `funnel`\n  + grep for words that end in `s` (plurals) \n  # Find lines that end with `s`\ngrep(\"s$\",adav$EVTYPE, ignore.case = TRUE, value = T)\n\n- Find similar values (words)\n- Choose a standard (lowercase, no symbols)\n\n#####\nhttps://biologyforfun.wordpress.com/2014/06/01/regular-expression-and-associated-functions-in-r/\n\n# regular expression with 5 different strings\nwords <- c(\"Bonjour\", \"Bienvenue\", \"Au revoir\", \"A la bonne heure\", \"2 heures\")\n#'\\\\w' will match any letters (a-z) present in the strings\ngrep(\"\\\\w\", words)  #there are letters in all elements of the string\n# now if we want to keep only elements having exactly 7 letters we use:\ngrep(\"\\\\w{7}\", words)\n# we can also match digits using '\\\\d', space '\\\\s' and their negation:\n# '\\\\W','\\\\D','\\\\S' could you guess what the coming regular expression\n# will match?\ngrep(\"\\\\w{2}\\\\W\\\\w+\", words, value = TRUE)\n# by placing '^' we match from the beginning of the string, similarly $ will\n# match the end\ngrep(\"^\\\\w{2}\\\\W\\\\w+$\", words, value = TRUE)\n# a last one using '\\\\d'\ngrep(\"\\\\d\\\\W\\\\w+\", words, value = TRUE)\n",
    "created" : 1453296516530.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2321110478",
    "id" : "ACDBD56A",
    "lastKnownWriteTime" : 1454152623,
    "path" : "C:/Users/Prem/Dropbox/Knowledge/STEM/Math/R_Statistics/Coursera/DataScienceSpCourseNotes/5_REPDATA/Assignment/project2/project2.RMD",
    "project_path" : "Assignment/project2/project2.RMD",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}