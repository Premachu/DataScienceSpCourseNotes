{
    "contents" : "---\ntitle: \"Reproducible Research Course Notes\"\nauthor: \"Prem Gill\"\noutput:\n  html_document:\n    highlight: pygments\n    toc: yes\n---\n\n## Reproducible research: concepts and ideas\n\n### Replication\n\n* ultimate standard for strengthening of scientific evidence\n* reproduce findings and conduct studies with independent investigators, data, labrotories, analytical methods\n* important in studies that affect policy\n* HOWEVER, some studies can't be replicated due to time/money/unique\n    * the middle ground between replication (gold) and no replication (bronze), is reproducibillity (silver)\n\n### Reproducibillity\n\n* Bridges gap between replication and leaving the study as it is (no replication), reproducbillity is a minimum standard \n* take data/code and replicate findings → validate their findings\n* Why do we need reproducible research \n    * datasets and studies are getting larger and more expensive, so not feasible to replicate\n* **Example**: Air Pollution Studies. Data is publically available, code for analytical methods used is provided. \n    * Looking for small health effects\n    * Important for informing policy\n    * Complex statistical methods are used\n    * By making the data reproducible, the same findings can be reproduced quickly and by anyone \n    \n* ***Research Pipeline***\n\n```{r fig.height = 5, fig.width = 7, fig.align='center', echo=FALSE,warning=FALSE}\n# install grid and png packages if not present\nlibrary(png)\nlibrary(grid)\ngrid.raster(readPNG(\"figures/1.jpg\"))\n```\n\n* **Necessities for Reproducible Research**\n    * Analytic data: data that was used for the analysis. Not raw data, which may include data not used in analysis\n    * Analytic code\n    * documentation of code and data\n    * Standard means of distribution\n    \n* **Challenges**\n  * authors make considerable effort to make data/results available\n\t* readers must download data/results individually and piece it all together\n\t* readers may not have the same resources as authors (computing clusters, etc.)\n\t* few tools for readers/authors\n\t* In reality, authors just put their content online (often disorganized, but there are some central databases for various fields) and readers have to find the data and piece it together\n\n### Literate/Statistical Programming\n* Notion of an article is a stream of **text** and **code**\n* original idea came from *Don Knuth*\n* statistical analysis is divided into text and code chunks\n\t* text explains whats going on\n\t* code loads data/computes results\n\t* presentation code formats results (tables, graphics, etc)\n* Literate Programming requires\n\t* **documentation language** - [***weave***] produce human-readable docs (HTML/PDF)\n\t* **programming language** - [***tangle***] produce machine-readable code\n* **Sweave** - original program in R designed to do literate programming\n\t* LaTeX for documentation, R for programming\n\t* developed by *Friedrich Leisch* (member of R core)\n\t* still maintained by R core\n\t* ***limitations***\n\t\t* focus on LaTeX, difficult to learn markup languages\n\t\t* lacks features like caching, multiple plots per chunk, mixing programming languages with many other technical terms\n\t\t* not frequently updated/actively developed\n* **`knitr`** = alternative literate programming package\n\t* R for programming (can use others as well)\n\t* LaTeX/HTML/Markdown for documentation\n\t* developed by Iowa grad student *Yihui Xie*\n* **reproducible research** = minimum standard for non-replicable/computationally intensive studies\n\t* infrastructure still need for creating/distributing reproducible documents\n  \n## Structure of Data Analysis\n\n### Key Challenge in Data Analysis\n\n> \"Ask yourselves, what problem have you solved, ever, that was worth solving, where you knew all of the given information in advance? Where you didn’t have a surplus of information and have to filter it out, or you had insufficient information and have to go find some?” - ***Dan Myer***\n\n* **Proper data analysis** \n\n* Science $\\rightarrow$ Data $\\rightarrow$ Applied Statistics $\\rightarrow$ Theoretical Statistics\n* properly using the combination of science/data/applied statistics = proper data analysis\n\n### Define general question\n\n* most powerful dimension reduction tool, narrowing down question reduces noise/simply problem\n* Narrowing down question removes variables. Height, location, sample. Reduces dimensionality of problem \n* Start with general question\n    * Can I automatically detect areas of plankton growth?\n* Make it concrete: translate question using data analysis terminology \n    * Can I use quantitative characeristics of SST images to classify areas around the coast of the UK as areas of high plankton growth? \n    \n\n### Define ideal Dataset [link](http://datascientistinsights.com/2013/01/29/six-types-of-analyses-every-data-scientist-should-know/)\n    * **Descriptive** - a whole population. All Pokemon\n    * Exploratory - random sample with many variables measured. \n        * Choose random pokemon, measure height, speed, attack\n    * inferential - the right population, randomly sampled (drawing conclusion from sample to larger popluation)\n        * Water and fire type. Water are quicker than fire in sea.\n    * predictive - training set and test data set. (build model and classifier)\n        * Pokemon raised by boys are stronger. \n    * causal - experimental data from randomised study\n        * if modify one thing, it causes another        \n    * Predictive = training set and dataset (need training and test data sets from the same population to build a model and classifier)\n\t  * Causal = (if this is modified, then that happens) experimental data from randomized study\n\t  * Mechanistic = data from all components of system that you want to describe\n### Determine what data you can access\n\n  * free data on the web. \n  * Sometimes if there's no data you will need to generate it your self\n\n### Obtain The Data\n* try to obtain the raw data and reference the source\n* if loading data from internet source, record at the minimum url and time of access\n\n### Clean The Data\n* raw data need to be processed to be fed into modeling program\n* if already processed, need to understand how and understand documentation on how the pre-processing was done\n* understanding source of data (i.e. survey - how survey was done?)\n* may need to reformat/subsample data $\\rightarrow$ need to record steps\n* determine if data is good enough to solve the problem $\\rightarrow$ if not, find other data/quit/change question to avoid misleading conclusions\n\n### Exploratory Data Analysis\n\n* **Subsampling dataset**\n* for the purpose of the SPAM question, data needs to be split into training and test set (Predictive)\n\n* model = email is spam or not spam\n* training = dataset used to build model\n* test = dataset used to determine how good model is at making predictions\n\n* **example** \n    * model =\n\n```{r warning = F}\n# If it isn't installed, install the kernlab package with install.packages()\nlibrary(kernlab)\ndata(spam)\n# Perform subsampling (coin is flipped to split data into 2 pieces)\nset.seed(3435)\ntrainIndicator = rbinom(4601, size = 1, prob = 0.5)\n# Roughly 2314 in one half and 2287 in other half \ntable(trainIndicator)\ntrainSpam = spam[trainIndicator == 1, ]\ntestSpam = spam[trainIndicator == 0, ]\n```\n\n* look at one/two-dimensional summaries of data: what data lookes like, what the distribution looks like, relationships between variables etc\n    * `names()`, `summary()`, `head()` = Rownames, frequency word counts\n    * `table(trainSpam$type)` = classification of emails (spam or not spam) \n* Check for missing data\n* Create exploratory plots = rough sense of what data looks like\n    * `plot(trainSpam$capitalAve ~ trainSpam$type)` = average number of capital letters.\n        * difficult to look at picture because data highly skewed\n        * If data is skewed and difficult to look at it, useful to look at log transformation of variable \n\t  * `plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)`\n\t\t- because data is skewed $\\rightarrow$ use `log`\n\t\t- a lot of zeroes $\\rightarrow$ `+1`, because taking log of zero does not make sense\n* Perform exploratory analysis (e.g. clustering)\n\nperform exploratory analysis (clustering)\n  * relationships between predictors\n\t* `plot(log10(trainSpam[, 1:4] + 1))` = some characteristics are related, some are not\n\t* log transformations diagrams between pairs of variables\n\n```{r fig.height = 3, fig.width = 3, fig.align='center', echo=FALSE}\ngrid.raster(readPNG(\"figures/2.jpg\"))\n```\n\n* hierarchical cluster analysis (**Dendrogram**) = what words/characteristics tend to cluster together\n\t* `hCluster = hclust(dist(t(trainSpam[, 1:57])))`\n\t\t* ***Note**: Dendrograms can be sensitive to skewness in distribution of individual variables, so maybe useful to transform predictor (see below) *\n\t* `hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))`\n\n```{r fig.height = 4, fig.width = 6, fig.align='center', echo=FALSE}\ngrid.raster(readPNG(\"figures/3.jpg\"))\n```\n\n### Statistical prediction / modeling \n \n* Once you have done exploratory analysis (uni-variate statistics (summary statistics), bi-variate statitics (plots) and clustering) you can move onto more sophisticated modelling and prediction modelling\n* Should be informed by the results of your exploratory analysis\n* Exact methods depend on the question of interest\n* processing/transformations should be accounted for when necesscary\n    * go through each variable in the dataset and fit logistic regression to see if we can predict if an email is spam or not by using a single variable\n\n```{r cache = TRUE, warning=FALSE}\ntrainSpam$numType = as.numeric(trainSpam$type) - 1\ncostFunction = function(x, y) sum(x != (y > 0.5))\ncvError = rep(NA, 55)\nlibrary(boot)\nfor (i in 1:55) {\n    # creates formula with one variable and the result\n    lmFormula = reformulate(names(trainSpam)[i], response = \"numType\")\n    glmFit = glm(lmFormula, family = \"binomial\", data = trainSpam)\n    # cross validated error\n    cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]\n}\n# Which predictor has minimum cross-validated error?\nnames(trainSpam)[which.min(cvError)]\n```\n\n* think about measures/sources of uncertainty\n\n```{r warning = FALSE, cache = TRUE}\n# Use the best model from the group\npredictionModel = glm(numType ~ charDollar,family=\"binomial\",data=trainSpam)\n# Get predictions on the test set\npredictionTest = predict(predictionModel,testSpam)\npredictedSpam = rep(\"nonspam\",dim(testSpam)[1])\n# Classify as 'spam' for those with prob > 0.5\npredictedSpam[predictionModel$fitted > 0.5] = \"spam\"\n# Classification table\ntable(predictedSpam, testSpam$type)\n# Error rate\n(61 + 458)/(1346 + 458 + 61 + 449)\n```\n\n* **Summary**\n1. Run a linear regression model through every variable, comparing it email type (spam, not spam)\n    \n2. Calculate CV error of each variable  \n- choose variable with lowest CV error this is the single variable which is best at prediciting spam  \n- variable with lowest error is `$`\n      \n3. Make model using `$`  \n- Make model using the variable of lowest error (`$`), comparing it to email type (spam, not spam)\n      \n4. Make predictions using model\n- Use model to make predictions on test data set, i.e. predict outcomes on test dataset to see how well we do\n- calculate error rate of model using classification table\n\n### Interpret Results\n\n* Use appropiate language \n    * describes\n    * correlates with/associated with\n    * leads to/causes\n    * predicts\n* Give an explanation\n    * Why certain models predict better than others\n* Interpret coefficients\n* interpret measures of uncertainty\n\n* **Example** \n  * The fraction of characters that are dollar signs can be used to predict if email is spam or not\n  * Anything with more than 6.6% dollar signs is classified as spam\n  * More dollar signs means more spam under our prediction\n  * Our test set error rate was 22.4%\n  \n### Challenge results\n\n* Challenge all steps\n  * Question\n  * Data source\n  * Processing\n  * Analysis\n  * Conclusions\n* Challenge measures of uncertainty. Are these appropiate measures of uncertainity? \n* Challenge choice of models. Why is your the suitable model for the problem? Why did you choose the parts in your models?\n* Think of potential alternative analysis. How could others expand on your study? Are there alternatives that are useful in some way or produce better predictions? \n\n### Synthesize/write-up results\n\n* Lead with question (gives context and understanding of problem)\n* Summarise analysis\n* Don't include every analysis, include it\n  * if it is needed for story\n  * if it is needed to address challenge\n* Order analysis according to story, rather than chronologically\n* Include pretty pictures that contribute to story so people understand what you mean in a picture or two\n\n* **Example**\n* Lead with question\n    * Can quantitative characteristics of email be used to classify them as SPAM/HAM\n* Describe the approach\n    * Collected data from UCL -> created training/test sets\n    * Explored relationships\n    * Choose logistic model on training set by cross validation\n        * Used linear regression model on training set and chose single variable predictor using cross validation \n    * Applied model to test set, 78% test accuracy\n* Interpret results\n    * Number of dollar signs seems reasonable, e.g `Make money with viagra $$!`\n* Challenge results\n    * 78% isn't that great\n    * I could use more variables\n    * Why logisitic regression? Could use more sophisticated model like non-linear.\n    \n### Create Reproducible Code\n* document your analysis as you do them using markdown or `knitr`\n  * preserve any R code or written summary in a single document using `knitr`\n* ensure all analysis is reproducible (standard that most data analysis are judged on)\n    \n* key data analysis files\n  * **data**: raw\n\t\t* should be store in analysis folder\n\t\t* if accessed from the web, include in README file the URL, where the data is from, what the data is, brief description of what it is for, date of access\n\t\t* if data is store in Git repository, can use the log to talk about the above info\n\t* **data**: processed\n\t\t* should be names so that its easy to see what script generated what data\n\t\t* In README, important to document what code files were used to transform raw data to processed data\n\t\t* processed data should be tidy/organized\n\t* **figures**: exploratory\n\t\t* made during process of analysis, not necessarily all part of final report\n\t\t* don’t need to be well formatted/annotated\n\t\t* need to be usable enough so that the author can easily understand what is being presented and how to reproduce it\n\t* **figures**: final\n\t\t* more polished, better organized, more readable, possibly multiple panels\n\t\t* usually a small subset or original exploratory figures (typical journal article contains 5-6 figures)\n\t\t* clearly labeled and well annotated, axes/color set to make figure clear\n\t* **R code**: raw/unused scripts\n\t\t* could be less commented, multiple versions\n\t\t* may include analyses that are later discarded\n\t\t* important to name/document appropriately to understand what was performed\n\t\t* placed in a separate part of the data analysis directory (separate from final)\n\t* **R code**: final scripts\n\t\t* clearly commented - small comments for what/when/why/how, big comment blocks for whole sections to explain what is being done\n\t\t* include processing details for the raw data\n\t\t* should pertain to only analyses that appear in in the final write up\n\t* **R code**: R markdown files\n\t\t* not necessary or require but useful to summarize parts of analysis\n\t\t* can be used to generate reproducible reports, as it can embed code and text into single document and processing the document into readable webpage/pdf doc\n\t\t* easy to create in Rstudio\n\t* **text**: README file\n\t\t* explain what is going on in project directory\n\t\t* not necessary if you have R markdown files (don’t separate analysis and code - literate programming principle)\n\t\t* should contain step-by-step instructions for how analysis was conducted, what code files are called first, what are used to process the data, what are used to fit models, what are used to generate figures, etc.\n\t* **text**: text of analysis/report\n\t\t* should include title, introduction/motivation for problem, the method (statistical method), the results (including measures of uncertainty) and conclusions (including pitfalls/problems)\n\t\t* coherent story from all analysis performed, but does not need to include all analysis performed but only the most important and relevant parts\n\t\t* should include references for statistical methods, software packages, implementation that were used (for reproducibility)\n* **Resources**\n\t* [Project template](http://projecttemplate.net/) = a external R package\n\t* [Managing a statistical analysis project guidelines and best practices](http://www.r-statistics.com/2010/09/managing-a-statistical-analysis-project-guidelines-and-best-practices/)\n\n## Coding standards in R\n\n* write code in text editor and save as text file\n* indenting (4 space minimum, 8 preferable)\n* limit the width of your code (80 columns)\n* limit the length of functions, splitting functions into seperate chunks\n\n\n## Markdown ([documentation](http://daringfireball.net/projects/markdown/syntax))\n* Markdown = text-to-HTML conversion tool for web writers.\n  * simplified version of markup language\n\t* write using easy-to-read, easy-to-write plain text format\n\t* any text editor can create markdown document\n\t* convert the text to structurally valid XHTML/HTML\n\t* created by John Gruber\n* **italics** = `*text*`\n* **bold** = `**text**`\n* **main heading** = `#Heading`\n* **secondary heading** = `##Heading`\n* **tertiary main heading** = `###Heading`\n* **unordered list** = `- first element`\n* **ordered list** = `1. first element`\n\t* the number in front actually doesn’t matter, as long as there is a number there, markdown will be compiled to an ordered list (no need for renumbering)\n* **links** = `[text](url)`\n\t* OR `[text][1]` $\\rightarrow$ later in the document, define all of the links in this format: `[1]: url \"text\"`\n* **new lines** = requires a ***double space*** after the end of a line\n\n\n\n## R Markdown\n* integration of R code and markdown\n\t* allows creating documents containing \"live\" R code\n\t* R code is evaluated as a part of the processing of the markdown\n\t* results from R code inserted into markdown document\n\t* core tool for literate statistical programming\n\t* **pros**\n\t\t* text/code all in one place in logical order\n\t\t* data/results automatically updated to reflect external changes\n\t\t* code is live = automatic test when building document\n\t* **cons**\n\t\t* text/code all in one place, can be difficult to read especially if there’s a lot of code\n\t\t* can substantially slowdown processing of documents\n* **`knitr` package**\n\t* written by YihuiXie, built into RStudio\n\t* support Markdown, LaTeX, HTML as documentation languages\n\t* Exports PDF/HTML\n\t* good for manuals, short/medium technical documents, tutorials, periodic reports, data preprocessing documents/summaries\n\t* not good for long research articles, complex time-consuming computations, precisely formatted documents\n\t* evaluates R markdown documents and return/records the results, and write out a Markdown files\n\t* Markdown file can then be converted into HTML using markdown package\n\t* solidify package converts R markdown into presentation slides\n* In RStudio, create new R Markdown files by clicking New $\\rightarrow$ R Markdown\n\t* `========` = indicates title of document (large text)\n\t* `$expression$` = indicates LaTeX expression/formatting\n\t* \\``text`\\` = changes text to code format (typewriter font)\n\t* \\`\\`\\``{r name, echo = FALSE, results = hide}...`\\`\\`\\` = R code chunk\n\t\t* `name` = name of the code chunk\n\t\t* `echo = FALSE` = turns off the echo of the R code chunk, which means display only the result\n\t\t* ***Note**: by default code in code chunk is echoed = print code AND results *\n\t\t* `results = hide` = hides the results from being placed in the markdown document\n\t* inline text computations\n\t\t* \\``r` `variable`\\` = prints the value of that variable directly inline with the text\n\t* incorporating graphics\n\t\t* \\`\\`\\``{r scatterplot, fig.height = 4, fig.width = 6} ... plot() ... `\\`\\`\\` = inserts a plot into markdown document\n\t\t\t* `scatterplot` = name of this code chunk (can be anything)\n\t\t\t* `fig.height = 4` = adjusts height of the figure, specifying this alone will produce a rectangular plot rather than a square one by default\n\t\t\t* `fig.width = 6` = adjusts width of the figure\n\t\t* knitr produces HTML, with the image embedded in HTML using base64 encoding\n\t\t\t* does not depend on external image files\n\t\t\t* not efficient but highly transportable\n\t* incorporating tables (xtable package: `install.packages(\"xtable\")`)\n\t\t* `xtable`prints the table in html format, which is better presented than plain text normally\n\n```{r showtable, results = \"asis\", fig.align = 'center'}\nlibrary(datasets)\nlibrary(xtable)\nfit <- lm(Ozone ~ Wind + Temp + Solar.R, data = airquality)\nxt <- xtable(summary(fit))\nprint(xt, \"html\")\n```\n\n* **setting global options**\n\t* \\`\\`\\``{r setoptions, echo = FALSE} opts_chunk$set(echo = FALSE, results = \"hide\")`\\`\\`\\` = sets the default option to not print the code/results unless otherwise specified\n* **common options**\n\t* **output**: `results = \"asis\"` OR `\"hide\"`\n\t\t* `\"asis\"` = output to stay in original format and not compiled into HTML\n\t* **output**: `echo = TRUE` OR `FALSE`\n\t* **figures**: `fig.height = numeric`\n\t* **figures**: `fig.width = numeric`\n* **caching computations**\n\t* add argument to code chunk: `cache = TRUE`\n\t* computes and stores result of code the first time it is run, and calls the stored result directly from file for each subsequent call\n\t* useful for complex computations\n\t* caveats:\n\t\t* if data/code changes, you will need to re-run cached code chunks\n\t\t* dependencies not checked explicitly (changes in other parts of the code $\\rightarrow$ need to re-run the cached code)\n\t\t* if code does something outside of the document (i.e. produce a png file), the operation cannot be cached\n* **\"Knit HTML\"** button to process the document\n\t* alternatively, when not in RStudio, the process can be accomplished through the following\n\n```r\nlibrary(knitr)\nsetwd(<working directory>)\nknit2html(\"document.Rmd\")\nbrowseURL(\"document.html\")\n```\n\n* processing of `knitr` documents\n\t* author drafts R Markdown (.Rmd) $\\rightarrow$ `knitr` processes file to Markdown (.md) $\\rightarrow$ `knitr` converts file to HTML\n\t* ***Note**: author should NOT edit/save the .md or .html document until you are done with the document *\n\n\n## Communicating Results\n* when presenting information, it is important to breakdown results of an analysis into different levels of granularity/detail\n* below are listed in order of ***least $\\rightarrow$ most specific***\n\n### Hierarchy of Information - Research Paper\n* **title/author list** = description of topic covered\n* **abstract** = a few hundred words about the problem, motivation, and solution\n* **body/results** = detailed methods, results, sensitivity analysis, discussion/implication of findings\n* **supplementary material/gory details** = granular details about analysis performed and method used\n* **code/really gory detail** = material to reproduce analysis/finding\n\n### Hierarchy of Information - Email Presentation\n* **subject line/sender** = must have, should be concise/descriptive, summarize findings in one sentence if possible\n* **email body** = should be 1-2 paragraphs, brief description of problem/context, summarize findings/results\n  - If action needs to be taken, suggest some options and make them as concrete as possible\n\t- If questions need to be addressed, try to make them yes/no\n* **attachment(s)** = R Markdown/report containing more details, should still stay concise (not pages of code)\n* **links to supplementary materials** = GitHub/web link to code, software, data\n\n### RPubs ([link](http://rpubs.com/))\n* built-in service with RStudio and works seamlessly with `knitr`\n* after kniting the R Markdown file in HTML, you can click on **Publish** to publish the HTML document on RPubs\n* _**Note**: all publications to RPups are publicly available immediately_\n\n## Reproducible Research Checklist\n* **Checklist**\n  * Are we doing good science?\n\t* Was any part of this analysis done by hand?\n\t\t- If so, are those parts *precisely* document?\n\t\t- Does the documentation match reality?\n\t* Have we taught a computer to do as much as possible (i.e. coded)?\n\t* Are we using a version control system?\n\t* Have we documented our software environment?\n\t* Have we saved any output that we cannot reconstruct from original data + code?\n\t* How far back in the analysis pipeline can we go before our results are no longer (automatically) reproducible?\n\n### Do\n* ***start with good science***\n    - coherent/focused question simplifies many problems\n    - choose something interesting that will motivate you\n    - collaborate with others to reinforce good practices and habits\n\n* ***teach a computer***\n\t- worthwhile to automate all tasks through script/programming\n\t- code = precise instructions to process/analyze data\n\t- teaching the computer almost guarantee's reproducibility\n\t- `download.file(\"url\", \"filename\")` = convenient way to download file\n\t\t+ full URL specified (instead series of links/clicks)\n\t\t+ name of file specified\n\t\t+ directory specified\n\t\t+ code can be executed in R (as long as link is available)\n\n* ***use version control***\n\t- GitHub/BitBucket are good tools\n\t- helps to slow down\n\t\t+ forces the author to think about changes made and commit changes and keep track of analysis performed\n\t- helps to keep track of history/snapshots\n\t- allows reverting to old versions\n\n* ***keep track of software environment***\n\t- some tools/datasets may only work on certain software/environment\n\t\t+ software and computing environment are critical to reproducing analysis\n\t\t+ everything should be documented\n\t- **computer architecture**: CPU (Intel, AMD, ARM), GPUs, 32 vs 64bit\n\t- **operating system**: Windows, Mac OS, Linux/Unix\n\t- **software toolchain**: compilers, interpreters, command shell, programming languages (C, Perl, Python, etc.), database backends, data analysis software\n\t- **supporting software/infrastructure**: Libraries, R packages, dependencies\n\t- **external dependencies**: web sites, data repositories (data source), remote databases, software repositories\n\t- **version numbers**: ideally, for everything (if available)\n\t- `sessionInfo()` = prints R version, operating system, local, base/attached/utilized packages\n\n* ***set random number generator seed***\n\t- random number generators produce pseudo-random numbers based on initial seed (usually number/set of numbers)\n\t\t+ `set.seed()` can be used to specify seet for random generator in R\n\t- setting seed allows stream of random numbers to be reproducible\n\t- whenever you need to generate steam of random numbers for non-trivial purpose (i.e. simulations, Markov Chain Monte Carlo analysis), ***always*** set the seed.\n\n* ***think about entire pipeline***\n\t- data analysis is lengthy process, important to ensure each piece is reproducible\n\t\t+ final product is important, but the process is just as important\n\t- raw data $\\rightarrow$ processed data $\\rightarrow$ analysis $\\rightarrow$ report\n\t- the more of the pipeline that is made reproducible, the more credible the results are\n\n### Don'ts\n* ***do things by hand***\n\t- may lead to unreproducible results\n\t\t+ edit spreadsheets using Excel\n\t\t+ remove outliers (without noting criteria)\n\t\t+ edit tables/figures\n\t\t+ validate/quality control for data\n\t- downloading data from website (clicking on link)\n\t\t+ need lengthy set of instructions to obtain the same data set\n\t- moving/split/reformat data (no record of what was done)\n\t- if necessary, manual tasks must be documented precisely (account for people with different background/context)\n\n* ***point and click***\n\t- graphical user interfaces (GUI) make it easy to process/analyze data\n\t\t+ GUIs are intuitive to use but actions are **difficult** to track and for others to reproduce\n\t\t+ some GUIs include log files that can be utilized for review\n\t- any interactive software should be carefully used to ensure all results can be reproduced\n\t- text editors are usually ok, but when in doubt, document it\n\n* ***save output for convenience***\n\t- avoid saving data analysis output\n\t\t+ tables, summaries, figures, processed, data\n\t- output saved stand-alone without code/steps on how it is produced is not reproducible\n\t- when data changes or error is detected in parts of analysis the output is dependent on, the original graph/table will not be updated\n\t- intermediate files (processed data) are ok to keep but clear/precise documentation must be created\n\t- should save the **data/code** instead of the output\n\n## Replication vs Reproducibility\n* **Replication**\n  - focuses on validity of scientific claim\n\t- if a study states \"if X is related to Y\" then we ask \"is the claim true?\"\n\t- need to reproduce results with new investigators, data, analytical methods, laboratories, instruments, etc.\n\t- particularly important in studies that can impact broad policy or regulatory decisions\n\t- stands as **ultimate standard** for strengthening scientific evidence\n\n* **Reproducibility**\n\t- focuses on validity of data analysis\n\t- \"Can we trust this analysis?\"\n\t- reproduce results new investigators, same data, same methods\n\t- important when replication is impossible\n\t- arguably a **minimum standard** for any scientific study\n\n### Background and Underlying Trend for Reproducibility\n* some studies cannot be replicated (money/time/unique/opportunistic) $\\rightarrow$ 25 year studies in epidemiology\n* technology increases rate of collection/complexity of data\n* existing databases merged to become bigger databases (sometimes used off-label) $\\rightarrow$ administrative data used in health studies\n* computing power allows for more sophisitcated analyses\n* \"computational\" fields are ubiquitous\n* all of the above leads to the following\n\t- analysis are difficult to describe\n\t- inadequate training in statistics/computing and cause errors to be more easily produced through the pipeline\n\t- large data throughput, complex analysis, and failure to explain the process can inhibit knowledge transfer\n\t- results are difficult to replicate (knowledge/cost)\n\t- complicated analyses are not as easily trusted\n\n\n### Problems with Reproducibility\n* aiming for reproducibility provides for\n\t- transparency of data analysis\n\t\t+ check validity of analysis $\\rightarrow$ people check each other $\\rightarrow$ \"self-correcting\" community\n\t\t+ re-run the analysis\n\t\t+ check the code for bugs/errors/sensitivity\n\t\t+ try alternate approaches\n\t* data/software/methods availability\n\t* improved transfer of knowledge\n\t\t- focuses on \"downstream\" aspect of research dissemination (does solve problems with erroneous analysis)\n* reproducibility does not guarantee\n\t- correctness of analysis (reproducible $\\neq$ true)\n\t- trustworthiness of analysis\n\t- deterrence of bad analysis\n\n\n### Evidence-based Data Analysis\n* create analytic pipelines from evidence-based components – standardize it ([\"Deterministic Statistical Machine\"](http://goo.gl/Qvlhuv))\n\t- apply thoroughly-studied (via statistical research), ***mutually-agreed-upon methods*** to analyze data whenever possible\n\t- once pipeline is established, shouldn’t change it (“transparent box”)\n\t* this reduces the \"researcher degrees of freedom\" (restricting the ability to alter different parts of analysis pipeline)\n\t\t+ analogous to a pre-specified clinical trial protocol\n\t- ***example***: time series of air pollution/health\n\t\t+ _key question_: \"Are short-term changes in pollution associated with short-term changes in a population health outcome?\"\n\t\t+ long history of statistical research investigating proper methods of analysis\n\t\t+ pipeline\n\t\t\t1. check for outliers, high leverage, overdispersion $\\rightarrow$ skewedness of data\n\t\t\t2. Fill in missing data? $\\rightarrow$ NO! (systematic missing data, imputing would add noise)\n\t\t\t3. model selection: estimate degrees of freedom to adjust for unmeasured confounding variables\n\t\t\t4. multiple lag analysis\n\t\t\t5. sensitivity analysis with respect to unmeasured confounder adjustment/influential points\n* this provides standardized, best practices for given scientific areas and questions\n* gives reviewers an important tool without dramatically increasing the burden on them\n* allows more effort to be focused on improving the quality of \"upstream\" aspects of scientific research\n    \n  \n\n## Case Study\n\n### Pokemon. (Fire and not fire) or Rare and not rare\n### Plankton. Areas of Plankton and not areas of high plankton growth\n\nlevel <- sample(1:99, 10, replace=T)\nhp <- sample(11:50, 10, replace=T)\natk <- rnorm(10, 10, 4)\ndata.frame(level, hp, atk)\n\nsample(1:151, 6)\n",
    "created" : 1452245360737.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "479605695",
    "id" : "2111A7D3",
    "lastKnownWriteTime" : 1452778557,
    "path" : "C:/Users/Prem/Dropbox/Knowledge/STEM/Math/R_Statistics/Coursera/DataScienceSpCourseNotes/5_REPDATA/Notes_Reproducible_Research.Rmd",
    "project_path" : "Notes_Reproducible_Research.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}